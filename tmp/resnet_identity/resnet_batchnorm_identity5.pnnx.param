7767517
29 28
pnnx.Input               pnnx_input_0             0 1 0 #0=(8,3,224,224)f32
nn.Conv2d                conv1                    1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,3,3,3)f32 #0=(8,3,224,224)f32 #1=(8,64,224,224)f32
nn.ReLU                  relu1                    1 1 1 2 #1=(8,64,224,224)f32 #2=(8,64,224,224)f32
nn.Conv2d                conv1_1                  1 1 2 3 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #2=(8,64,224,224)f32 #3=(8,64,224,224)f32
nn.ReLU                  relu1_1                  1 1 3 4 #3=(8,64,224,224)f32 #4=(8,64,224,224)f32
nn.Conv2d                conv1_2                  1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #4=(8,64,224,224)f32 #5=(8,64,224,224)f32
pnnx.Expression          pnnx_expr_7              2 1 2 5 6 expr=add(@0,@1) #2=(8,64,224,224)f32 #5=(8,64,224,224)f32 #6=(8,64,224,224)f32
nn.ReLU                  relu2                    1 1 6 7 #6=(8,64,224,224)f32 #7=(8,64,224,224)f32
nn.Conv2d                conv2_11                 1 1 7 8 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,64,3,3)f32 #7=(8,64,224,224)f32 #8=(8,128,112,112)f32
nn.ReLU                  relu2_11                 1 1 8 9 #8=(8,128,112,112)f32 #9=(8,128,112,112)f32
nn.Conv2d                conv2_12                 1 1 9 10 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 #9=(8,128,112,112)f32 #10=(8,128,112,112)f32
nn.Conv2d                conv2_21                 1 1 7 11 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,64,1,1)f32 #7=(8,64,224,224)f32 #11=(8,128,112,112)f32
pnnx.Expression          pnnx_expr_5              2 1 10 11 12 expr=add(@0,@1) #10=(8,128,112,112)f32 #11=(8,128,112,112)f32 #12=(8,128,112,112)f32
nn.ReLU                  relu3                    1 1 12 13 #12=(8,128,112,112)f32 #13=(8,128,112,112)f32
nn.Conv2d                conv3_11                 1 1 13 14 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(256)f32 @weight=(256,128,3,3)f32 #13=(8,128,112,112)f32 #14=(8,256,56,56)f32
nn.ReLU                  relu3_11                 1 1 14 15 #14=(8,256,56,56)f32 #15=(8,256,56,56)f32
nn.Conv2d                conv3_12                 1 1 15 16 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 #15=(8,256,56,56)f32 #16=(8,256,56,56)f32
nn.Conv2d                conv3_21                 1 1 13 17 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(256)f32 @weight=(256,128,1,1)f32 #13=(8,128,112,112)f32 #17=(8,256,56,56)f32
pnnx.Expression          pnnx_expr_3              2 1 16 17 18 expr=add(@0,@1) #16=(8,256,56,56)f32 #17=(8,256,56,56)f32 #18=(8,256,56,56)f32
nn.ReLU                  relu4                    1 1 18 19 #18=(8,256,56,56)f32 #19=(8,256,56,56)f32
nn.Conv2d                conv4_11                 1 1 19 20 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(512)f32 @weight=(512,256,3,3)f32 #19=(8,256,56,56)f32 #20=(8,512,28,28)f32
nn.ReLU                  relu4_11                 1 1 20 21 #20=(8,512,28,28)f32 #21=(8,512,28,28)f32
nn.Conv2d                conv4_12                 1 1 21 22 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,3,3)f32 #21=(8,512,28,28)f32 #22=(8,512,28,28)f32
nn.Conv2d                conv4_21                 1 1 19 23 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(512)f32 @weight=(512,256,1,1)f32 #19=(8,256,56,56)f32 #23=(8,512,28,28)f32
pnnx.Expression          pnnx_expr_1              2 1 22 23 24 expr=add(@0,@1) #22=(8,512,28,28)f32 #23=(8,512,28,28)f32 #24=(8,512,28,28)f32
nn.ReLU                  relu5                    1 1 24 25 #24=(8,512,28,28)f32 #25=(8,512,28,28)f32
nn.AdaptiveAvgPool2d     avgpool                  1 1 25 26 output_size=(1,1) #25=(8,512,28,28)f32 #26=(8,512,1,1)f32
Tensor.view              Tensor.view_0            1 1 26 27 shape=(8,-1) $input=26 #26=(8,512,1,1)f32 #27=(8,512)f32
pnnx.Output              pnnx_output_0            1 0 27 #27=(8,512)f32
